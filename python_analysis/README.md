# ğŸš€ Enhanced Reddit Problem Discovery

AI-powered tool to discover business opportunities from Reddit discussions with cost optimization, sentiment analysis, and comprehensive insights.

## âœ¨ New Enhanced Features

- **ğŸ’° Cost Optimization**: Smart filtering reduces API costs by 50-70%
- **ğŸ˜Š Sentiment Analysis**: Finds higher quality problems through emotional analysis
- **ğŸ• Temporal Patterns**: Analyzes when problems are posted for timing insights
- **ğŸ‘¥ User Behavior**: Tracks who posts problems and repeat patterns
- **ğŸ“Š Advanced Visualizations**: Interactive charts and word clouds
- **ğŸ”„ Incremental Analysis**: Only analyzes new problems since last run
- **âš™ï¸ Dynamic Clustering**: Optimizes cluster count using silhouette analysis
- **ğŸ“ˆ Enhanced Reporting**: Comprehensive insights with cost tracking
- **ğŸš€ Delta Harvesting**: Only fetch new content since last harvest (90-95% faster)
- **ğŸ’¾ Database Storage**: Persistent SQLite storage with full-text search
- **ğŸ¤– Smart Automation**: Scheduled harvesting with frequency-based strategies

## ğŸ“ Files

- `harvest_reddit.py` - Original harvester for posts and comments
- `harvest_reddit_enhanced.py` - **NEW: Enhanced harvester with delta fetching**
- `delta_scheduler.py` - **NEW: Automated scheduling for regular harvests** 
- `analyze_problems.py` - **Enhanced analyzer** with cost optimization + advanced features
- `run_analysis.py` - **Enhanced orchestrator** for easy pipeline management
- `config.json` - Configuration file for all parameters (now includes delta settings)
- `requirements.txt` - Python dependencies
- `setup.sh` - **NEW: Automated setup script**

## ğŸš€ Quick Start

### ğŸ› ï¸ Setup (First Time)

```bash
# Method 1: Automated setup (recommended)
chmod +x setup.sh
./setup.sh

# Method 2: Manual setup
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### ğŸ“Š Basic Usage

```bash
# Activate virtual environment (if not using setup.sh)
source venv/bin/activate

# Check system status
python3 run_analysis.py status

# Run enhanced analysis with default subreddits
python3 run_analysis.py analyze

# List available preset subreddit groups
python3 run_analysis.py --list-groups

# Harvest and analyze specific subreddits
python3 run_analysis.py full --subreddits entrepreneur startups

# Use preset groups
python3 run_analysis.py full --subreddits group:finance group:tech

# Basic analysis without enhanced features
python3 run_analysis.py analyze --basic
```

## ğŸš€ Delta Harvesting (DEFAULT)

The enhanced harvester now uses **smart delta fetching by default** - only collecting new content since your last harvest. This provides a **90-95% speed improvement** and is perfect for regular monitoring.

### âš¡ Quick Commands (NEW Default Behavior)

```bash
# Smart harvesting (DEFAULT - fast delta updates)
python3 harvest_reddit_enhanced.py --subreddits PersonalFinanceNZ

# Multiple subreddits (all use smart delta)
python3 harvest_reddit_enhanced.py --subreddits PersonalFinanceNZ entrepreneur startups

# Check what's in your database
python3 harvest_reddit_enhanced.py --stats

# Force full harvest only if you need comprehensive historical data
python3 harvest_reddit_enhanced.py --subreddits PersonalFinanceNZ --mode full
```

### ğŸ”„ Smart vs Full Harvesting

```bash
# SMART MODE (DEFAULT) - Recommended for regular use
# âœ… 10-30 seconds vs 3-5 minutes
# âœ… Only fetches new content
# âœ… No duplicates
# âœ… Resumable if interrupted
python3 harvest_reddit_enhanced.py --subreddits PersonalFinanceNZ

# FULL MODE - Only when you need comprehensive data
# âš ï¸  3-5 minutes per subreddit 
# âš ï¸  Gets all posts (including old ones)
# âš ï¸  Can be interrupted by rate limits
python3 harvest_reddit_enhanced.py --subreddits PersonalFinanceNZ --mode full
```

### ğŸ¤– Automated Scheduling

```bash
# Check what's due for harvest
python3 delta_scheduler.py --status

# Run scheduled harvests (based on frequency settings)
python3 delta_scheduler.py --run

# Force harvest specific subreddits
python3 delta_scheduler.py --force PersonalFinanceNZ entrepreneur
```

### âš¡ Performance Comparison

| Aspect | Old Default (Full) | NEW Default (Smart) |
|--------|-------------|---------------|
| Time | 3-5 minutes | **10-30 seconds** |
| API Calls | 800-1500 | **50-200** |
| Storage | Duplicates | **Incremental only** |
| Interruption Handling | Lost progress | **Resumable** |
| Real-time Monitoring | No | **Yes** |
| First Run | Full harvest | **Recent posts (smart)** |
| Subsequent Runs | Full harvest | **Only new content** |

## ğŸ¯ Subreddit Management

### ğŸ“¦ Preset Groups
The system includes preset subreddit groups for common analysis scenarios:

- **finance**: PersonalFinance, PersonalFinanceNZ, Fire, investing, financialindependence
- **tech**: programming, webdev, startups, entrepreneur, SaaS  
- **business**: entrepreneur, startups, smallbusiness, marketing, sales
- **productivity**: productivity, getmotivated, organization, TimeManagement
- **health**: fitness, nutrition, mentalhealth, loseit, getmotivated
- **education**: studytips, college, university, OnlineEducation, learnprogramming
- **remote_work**: remotework, digitalnomad, WorkFromHome, freelance
- **popular**: AskReddit, LifeProTips, unpopularopinion, mildlyinfuriating

### ğŸ” Subreddit Commands

```bash
# List all preset groups
python3 run_analysis.py --list-groups

# Validate subreddits before harvesting
python3 run_analysis.py --validate-subs entrepreneur programming nonexistent

# Harvest specific subreddits
python3 run_analysis.py harvest --subreddits PersonalFinanceNZ entrepreneur

# Use preset groups
python3 run_analysis.py harvest --subreddits group:finance

# Mix preset groups and individual subreddits
python3 run_analysis.py harvest --subreddits group:tech productivity

# Custom posts per subreddit
python3 run_analysis.py harvest --subreddits group:business --posts-per-sub 300
```

## ğŸ§  Enhanced Analysis Pipeline

1. **Load Configuration** - Reads config.json for all parameters
2. **Harvest** - Collects posts and comments from Reddit
3. **Extract & Filter** - Finds problems with sentiment analysis and confidence scoring
4. **Incremental Check** - Only processes new problems since last run (optional)
5. **Enhanced Analytics** - Temporal, emotional, and user pattern analysis
6. **Smart Clustering** - Dynamic cluster optimization with silhouette analysis
7. **Cost-Optimized AI** - Only analyzes high-value clusters with GPT-4
8. **Visualization** - Creates charts, word clouds, and interactive plots
9. **Comprehensive Report** - Enhanced insights with cost tracking

## ğŸ¯ Enhanced Features

### ğŸ’° Cost Optimization
- **Smart Filtering**: Only analyzes clusters meeting quality thresholds
- **API Limits**: Configurable maximum API calls per run
- **Cost Tracking**: Real-time cost estimation and savings reporting
- **Efficiency Metrics**: Tracks percentage of clusters skipped

### ğŸ˜Š Advanced Analytics
- **Sentiment Analysis**: Uses TextBlob to identify negative sentiment problems
- **Emotion Mapping**: Detects frustration, anger, confusion, desperation
- **Temporal Patterns**: Analyzes peak problem posting times and days
- **User Behavior**: Tracks repeat problem posters and patterns

### ğŸ“Š Visualizations
- **Sentiment Distribution**: Histogram of problem sentiment scores
- **Cluster Analysis**: Bar charts of cluster sizes and engagement
- **Temporal Charts**: Hourly and daily problem posting patterns
- **Emotion Patterns**: Emotional intensity across problem types
- **Word Clouds**: Most common terms in problems
- **Scatter Plots**: Engagement vs sentiment analysis

### âš™ï¸ Configuration Options

Edit `config.json` to customize:

```json
{
  "analysis": {
    "min_problem_confidence": 0.35,
    "min_cluster_size_for_ai": 5,
    "max_api_calls": 50
  },
  "cost_optimization": {
    "enable_smart_filtering": true,
    "estimated_cost_per_call": 0.002
  },
  "visualization": {
    "enable_charts": true
  },
  "incremental": {
    "enable_incremental": true
  }
}
```

## ğŸ“Š Enhanced Output

The enhanced analysis generates:

### ğŸ“ˆ Enhanced Report (`enhanced_report_*.md`)
- **Executive Summary**: API usage, cost savings, efficiency metrics
- **Enhanced Analytics**: Temporal patterns, emotional analysis, user behavior
- **Top Opportunities**: AI-analyzed business opportunities with detailed scores
- **Methodology**: Comprehensive explanation of analysis approach

### ğŸ“‹ Raw Data (`enhanced_opportunities_*.json`)
- Complete analysis results with metadata
- Temporal, emotional, and user analysis data
- API usage tracking and cost information
- Analysis configuration used

### ğŸ“Š Visualizations (`output/charts/`)
- `sentiment_distribution.png` - Problem sentiment histogram
- `cluster_sizes.png` - Cluster size analysis
- `engagement_sentiment.png` - Engagement vs sentiment scatter plot
- `temporal_patterns.png` - Hourly and daily problem patterns
- `emotion_patterns.png` - Emotional intensity analysis
- `problem_wordcloud.png` - Most common problem terms

## ğŸ¯ Use Case Examples

### ğŸ’° Financial Analysis
```bash
# Analyze financial communities for fintech opportunities
python3 run_analysis.py full --subreddits group:finance --posts-per-sub 300

# Focus on specific financial problems
python3 run_analysis.py full --subreddits PersonalFinance Fire investing
```

### ğŸš€ Startup & Tech Analysis  
```bash
# Discover problems in tech/startup space
python3 run_analysis.py full --subreddits group:tech group:business

# Focus on productivity tools market
python3 run_analysis.py full --subreddits group:productivity group:remote_work
```

### ğŸ“ Education Market Research
```bash
# Find problems in education/learning
python3 run_analysis.py full --subreddits group:education learnprogramming

# Mixed analysis for broad market insights
python3 run_analysis.py full --subreddits group:popular productivity entrepreneur
```

## âš™ï¸ Advanced Usage

```bash
# Custom analysis with specific parameters
python3 run_analysis.py analyze --max-problems 2000 --clusters 25

# Use custom configuration file
python3 run_analysis.py analyze --config my_config.json

# Analyze specific harvest file
python3 run_analysis.py analyze --harvest-file my_data.json

# High-volume harvest for comprehensive analysis
python3 run_analysis.py harvest --subreddits group:finance --posts-per-sub 500

# Multi-group analysis with custom naming
python3 run_analysis.py harvest --subreddits group:tech group:business --output-name tech_business_combo

# Direct analysis script (advanced users)
python3 analyze_problems.py --enhanced --max-problems 1000 --clusters 15

# Harvest-only with validation
python3 harvest_reddit.py --subreddits entrepreneur startups --validate
```

## ğŸ’° Cost Optimization Examples

```bash
# Low-cost run (max 10 API calls)
# Edit config.json: "max_api_calls": 10
python3 run_analysis.py analyze

# High-quality run (max 100 API calls)
# Edit config.json: "max_api_calls": 100
python3 run_analysis.py analyze

# Check what would be analyzed without API calls
# Edit config.json: "max_api_calls": 0
python3 run_analysis.py analyze
```

## ğŸ“‹ Requirements

- **Environment**: Reddit API credentials in `../.env.local`
- **OpenAI**: API key for GPT-4 analysis
- **Python**: 3.8+ with required packages

```bash
# Install dependencies
pip install -r requirements.txt

# Check system status
python3 run_analysis.py status
```

## ğŸ¯ Cost & Performance

- **Base Cost**: ~$0.002 per API call to GPT-4o-mini
- **Smart Filtering**: Reduces costs by 50-70% through intelligent cluster selection
- **Typical Run**: 15-50 API calls = $0.03-$0.10 total cost
- **High-Value Focus**: Only analyzes clusters with strong business potential
